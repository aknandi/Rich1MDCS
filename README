---------------------------------------
------- Anita Nandi 7 Feb 2017 --------
--- Usage of the RICH1MDCS software ---
---------------------------------------

The MDCS analysis is divided into 4 steps:
1) Peak finding
2) Pattern cleaning
3) Calibration parameters fitting
4) Create DB slice

---------------------------------------
---------------------------------------
1. Peak finding
---------------------------------------
---------------------------------------

Using GaudiPython script under python/runMDCSPeakFinder.py
A Brunel algorithm (MDMRich1Algorithm) runs on raw data. Run on lxplus
It will search for the data in the local disk first (if you have downloaded the data locally), if the data is not found it will search on CASTOR

The files on castor must be staged before they can be accessed by the script (there will be 3 or 4 raw files for 1 scan)

>> stager_get -M /castor/cern.ch/grid/lhcb/data/2016/RAW/FULL/RICH1/TEST/171282/171282_0000000001.raw

The number 171282 is the run number of the MDCS scan, which can be found from the LHCb logbook. 
In order to check if the file is staged

>> stager_qry -M /castor/cern.ch/grid/lhcb/data/2016/RAW/FULL/RICH1/TEST/171282/171282_0000000001.raw

After staging you can copy them to eos /eos/lhcb/user/{initial}/{username}/RichMDCS/{year}/{runNo}/ if you want. This will give you a local copy of all the scans to run over whenever is required

>> rfcp /castor/cern.ch/grid/lhcb/data/2016/RAW/FULL/RICH1/TEST/171282/171282_0000000001.raw /eos/lhcb/user/{initial}/{username}/RichMDCS/{year}/{runNo}/


>> SetupProject Brunel v49r2p1

To see details of possible options:

>> python runMDCSPeakFinder.py -h 


To run normally (with no additional options):

>> python runMDCSPeakFinder.py --RunNumber=171282

This will run on all steps and give an ntuple to be processed in the cleaning called "NTuples_Run171282_AllSteps.root"
This takes several hours to run (~3-4 hours). I usually ran this on the lxplus batch system with the batchjobs/RichMDCS.sh script

>> bsub -q 1nd -J RichMDMS RichMDCS.sh

Another script accepts almost the same options but submits the jobs to LSF (lxplus only) through ganga, run with

>> ganga runMDCSPeakFinder_ganga.py

This option was old advice from Andrea, and I never used it.


---------------------------------------
---------------------------------------
2. Pattern cleaning
---------------------------------------
---------------------------------------

This is a simple ROOT/rooFit C++ script. It is compiled automatically when you "make" the package.
The executable is under scripts/PatternCleaning.exe. This is run with:

>> PatternCleaning.exe ../python/NTuples_Run171282_AllSteps.root

where "NTuples_Run171282_AllSteps.root" is the output filename form the peak finding

After ~3 minutes you will get 2 ntuples, 1 for each HPD box (U or D):
NTuple_Run171282_afterProcess_U.root
NTuple_Run171282_afterProcess_D.root

These ntuples contain various control plots and an ntuple with the cleaned peak that will be further processed in 3.
In order to quickly check that everything is ok, check the canvas "can_All_Peaks" in the root file. All the peaks found on each HPD should appear here. There may be missing hpds.
This may either be caused by wrong DB tags during step 1 or simply because the are disabled for whatever reason. 
Nothing to worry about in the latter case, otherwise go back to step 1 logs and see if there is something wrong.

You can also look at the pattern after the cleaning "can_Final".
Other useful distributions to check: "rooFit_xdiff", "rooFit_prop", "rooFit_npes", "rooFit_max" and "DLL_tot"
You may also change the DLL cut by changing the value of the global variable "double DLL_CUT=-2" at the beginning of scripts/Functions4Cleaning.C (and re-compile of course)


---------------------------------------
---------------------------------------
3. Calibration parameters fitting
---------------------------------------
---------------------------------------

Again you need to run a GaudiPython script: python/runMDCSParamFitter.py
The algorithm called is "MDMFitParameters"
Upper and lower box are processed separately (option --Rich1Panel) and you need to know the magnet polarity of the scan:

>> python runMDCSParamFitter.py --RunNumber=171282 --MagPolarity=Down --Rich1Panel=D --InputFile=../scripts/NTuple_Run171282_afterProcess_D.root --RandomSeed=0 --RadiusFactor=1 --Systematics=0
>> python runMDCSParamFitter.py --RunNumber=171282 --MagPolarity=Down --Rich1Panel=U --InputFile=../scripts/NTuple_Run171282_afterProcess_U.root --RandomSeed=0 --RadiusFactor=1 --Systematics=0

The last three options (RandomSeed, RadiusFactor and Systematics) are options added by Donal to experiment with the code, which are required for it to run properly. 
Don't worry about what the numbers are, they don't do anything important to the output
These will take ~2-3 minutes each to run

To list all options:

>> python runMDCSParamFitter.py -h
 

You will get a root file with control plots (way more than what you need) and an 4 xml files, two with the new and two with the previus parameters 
(I would ignore the previous one, as I don't think it gets filled reliably!)
There is one xml file for each HPD box.

In order to produce a full set of parameters for the CondDB you need to process two scans of opposite polarity (Up or Down). Useful output files:

MDCSParameters_Run171282_MagnetDown_D_RadiusChange_1percent_0.xml
MDCSParameters_Run171282_MagnetDown_U_RadiusChange_1percent_0.xml
MDCSParameters_Run171986_MagnetUp_D_RadiusChange_1percent_0.xml
MDCSParameters_Run171986_MagnetUp_U_RadiusChange_1percent_0.xml

where 171282 is the run number of the MagDown MDCS scan and 171986 is the run number of the MagUp MDCS scan 


---------------------------------------
---------------------------------------
4. Create DB slice
---------------------------------------
---------------------------------------

This needs to be done in CreateDBLayer directory

The content of these output files can be copied and pasted into one xml file (HPD.xml) in distinct blocks (to make it human readable replace "><" with ">\n<").
There's an example HPD.xml in doc/, with distinct blocks of parameters. Mag Up U box, Mag Up D box, Mag Down U box and Mag Down D box.

It may be necessary to provide a -3% scaling to the radius parameters in the xml file. Donal showed that this improved the Cherekov angle resolution
This can be achieved by running the CreateDBLayer/radiusScaling.py script, you need to modify the input and output xml file names. The scaling is given as an input

>> python radiusScaling.py -3

Move the HPD.xml file to SOMEPATH/Conditions/Rich1/Environment/
The DBpath created is /Conditions/Rich1/Environment/ which has to match the path in the CondDBBrowser

In CreateDBLayer.py:
upAlign = SOMEPATH
dnAlign = SOMEPATH
datetime.datetime( ) - set this to the time the condition is valid from (see interval of validity, IOV). These are the start and end dates for the condition

>> SetupProject LHCbDirac v8r2p55
>> SetupProject LHCb v40r4
>> python CreateDBLayer.py

This produces a DB slice e.g. MDCS-RICH1-07022017.db
This can be given to Antonis or Chris to add to the LHCb CondDB


Anita Nandi
07 Feb 2017
